# movement/navigation.py

import time
import math
import cv2
import numpy as np # NÃ©cessaire pour la vÃ©rification de luminositÃ©
from vision.camera import get_frame
from vision.detection import detect_nao

# ==============================================================
# === GÃ‰NÃ‰RATEURS DE MOUVEMENT =================================
# ==============================================================


from fonction_score import Seeker, Explorer
from vision.camera import get_frame
from vision.detection import detect_nao


def run_algo_on_robot(session, grid_map):
    motion = session.service("ALMotion")
    
    # 1. Configurer le robot virtuel (Seeker) au mÃªme endroit que le vrai robot
    # Attention : x, y sont des indices de case (ex: 60, 10)
    seeker = Seeker(pos=(60, 10), vision_angle=70, max_distance=300, 
                    direction_angle=0, grid=grid_map, target=[], size=10)
    
    explorer = Explorer(seeker)
    current_path = []
    METERS_PER_CELL = 0.04  # Ã€ ajuster : 1 case = 4 cm ?

    print("ðŸš€ DÃ©marrage Algo A* sur le vrai robot...")
    motion.wakeUp()

    while True:
        # --- A. Partie Algorithme (Cerveau) ---
        explorer.mettre_a_jour_vue()
        
        # Si pas de chemin, on cherche une cible
        if not current_path:
            target = explorer.trouver_cible_lointaine()
            if target is None:
                print("Exploration finie.")
                break
            
            path = explorer.trouver_chemin_astar((seeker.x, seeker.y), target)
            if path:
                current_path = path
            else:
                # Blocage virtuel -> Rotation rÃ©elle et virtuelle
                print("Rotation de dÃ©blocage")
                seeker.tourner(45)
                motion.moveTo(0, 0, math.radians(45))
                continue

        # --- B. Partie Mouvement (Jambes) ---
        if current_path:
            next_x, next_y = current_path.pop(0)
            
            # Calcul du mouvement rÃ©el
            dx = next_x - seeker.x
            dy = next_y - seeker.y
            dist_m = math.sqrt(dx**2 + dy**2) * METERS_PER_CELL
            
            # Calcul de l'angle
            angle_target = math.atan2(dy, dx)
            angle_robot = math.radians(seeker.direction_angle)
            rotation = angle_target - angle_robot
            rotation = (rotation + math.pi) % (2 * math.pi) - math.pi # Normalisation

            # ExÃ©cution physique
            if abs(rotation) > 0.1:
                motion.moveTo(0, 0, rotation)
            motion.moveTo(dist_m, 0, 0)
            
            # Mise Ã  jour virtuelle
            seeker.x, seeker.y = next_x, next_y
            seeker.direction_angle = math.degrees(angle_target) % 360

def drive_robot_with_algo(session, video_service, model, class_names, tts, name_id, grid_map):
    """
    Pilote le robot en utilisant la logique de l'Explorer (A*).
    """
    motion_service = session.service("ALMotion")
    memory_service = session.service("ALMemory")
    
    # --- CONFIGURATION ---
    # Ã‰chelle : Combien de mÃ¨tres mesure une case de votre grille ?
    # Exemple : Si votre carte fait 3.5m de large et la grille 350 pixels, SCALE = 0.01 (1cm)
    CELL_SIZE = 0.04  # 4 cm par case (Ã  ajuster selon la taille rÃ©elle de votre arÃ¨ne)
    
    # Initialisation du robot virtuel (Seeker)
    # Attention : Il faut que la position de dÃ©part (start_x, start_y) corresponde Ã  la rÃ©alitÃ© !
    start_x, start_y = 60, 10  # Exemple arbitraire, Ã  calibrer
    
    seeker = Seeker(
        pos=(start_x, start_y),
        vision_angle=70,
        max_distance=300, # En cases
        direction_angle=0,
        grid=grid_map,
        target=[], # On ne connait pas la cible rÃ©elle, c'est ce qu'on cherche
        size=10 # Taille du robot en cases
    )
    
    explorer = Explorer(seeker)
    current_path = []
    
    print("ðŸš€ DÃ©marrage de la navigation algorithmique...")
    motion_service.wakeUp()
    
    # Boucle principale (similaire Ã  recherche_affichage mais physique)
    while True:
        # 1. VÃ©rification Visuelle (Est-ce que je vois l'autre robot ?)
        frame = get_frame(video_service, name_id)
        if frame is not None:
            detected, class_name, conf = detect_nao(frame, model, class_names)
            if detected:
                print(f"âœ… CIBLE TROUVÃ‰E : {class_name} ({conf:.2f})")
                tts.say(f"J'ai trouvÃ© {class_name} !")
                motion_service.stopMove()
                break # Fin du jeu
        
        # 2. Mise Ã  jour de la carte mentale (Virtuel)
        explorer.mettre_a_jour_vue()
        
        # 3. DÃ©cision du prochain mouvement
        if not current_path:
            # Si pas de chemin, on cherche une nouvelle cible inexplorÃ©e
            target_pos = explorer.trouver_cible_lointaine()
            
            if target_pos is None:
                print("ðŸ Exploration terminÃ©e (tout est vu).")
                tts.say("J'ai fini d'explorer.")
                break
                
            print(f"ðŸ“ Nouvelle cible algorithmique : {target_pos}")
            path = explorer.trouver_chemin_astar((seeker.x, seeker.y), target_pos)
            
            if path:
                current_path = path
            else:
                # Blocage : on fait une rotation sur place pour dÃ©bloquer la vue/A*
                print("âš ï¸ Pas de chemin, rotation de secours.")
                motion_service.moveTo(0, 0, math.radians(45))
                seeker.tourner(45)
                continue

        # 4. ExÃ©cution du mouvement (Physique)
        if current_path:
            next_x, next_y = current_path.pop(0)
            
            # Calcul du dÃ©placement en cases
            dx = next_x - seeker.x
            dy = next_y - seeker.y
            
            if dx == 0 and dy == 0:
                continue
                
            # Calcul de l'angle et de la distance pour le monde rÃ©el
            dist_meters = math.sqrt(dx**2 + dy**2) * CELL_SIZE
            
            # Orientation : Le robot doit se tourner vers la case cible
            # L'angle cible dans la grille (0Â° = Est, 90Â° = Sud dans votre code fonction_score ?)
            # VÃ©rifions votre code : 0->(1,0) (Est), 90->(0,1) (Sud). C'est standard image.
            target_angle_rad = math.atan2(dy, dx)
            
            # Conversion de l'angle absolu grille en angle relatif robot
            # On assume que seeker.direction_angle est en degrÃ©s et absolu
            current_angle_rad = math.radians(seeker.direction_angle)
            rotation_needed = target_angle_rad - current_angle_rad
            
            # Normalisation de l'angle (-pi Ã  pi)
            rotation_needed = (rotation_needed + math.pi) % (2 * math.pi) - math.pi
            
            # --- COMMANDE MOTEUR ---
            # On tourne d'abord (si nÃ©cessaire) puis on avance
            if abs(rotation_needed) > 0.1: # Si rotation significative
                motion_service.moveTo(0, 0, rotation_needed)
            
            motion_service.moveTo(dist_meters, 0, 0)
            
            # 5. Mise Ã  jour de la position virtuelle
            seeker.x = next_x
            seeker.y = next_y
            # Mise Ã  jour de l'angle virtuel (on arrondit comme dans votre algo)
            new_angle_deg = math.degrees(math.atan2(dy, dx))
            seeker.direction_angle = round(new_angle_deg / 45) * 45 % 360
            
            # (Optionnel) VÃ©rification Sonar pour Ã©viter les vrais murs non cartographiÃ©s
            l = memory_service.getData("Device/SubDeviceList/US/Left/Sensor/Value")
            r = memory_service.getData("Device/SubDeviceList/US/Right/Sensor/Value")
            if l < 0.4 or r < 0.4:
                print("ðŸ›‘ Obstacle imprÃ©vu dÃ©tectÃ© !")
                motion_service.stopMove()
                # Ici, il faudrait idÃ©alement mettre Ã  jour la grille (grid_map) avec un mur
                # explorer.knowledge_map[ny][nx] = 2 
                current_path = [] # On force le recalcul d'un chemin

    motion_service.rest()

def rotate_on_place_generator(motion_service, num_steps=8, step_deg=45, pause=0.3):
    """Effectue une rotation complÃ¨te sur place."""
    step_rad = math.radians(step_deg)
    for i in range(num_steps):
        motion_service.moveTo(0.0, 0.0, step_rad)
        time.sleep(pause)
        yield True

def cautious_forward_generator(motion_service, memory_service, num_steps=5, step=0.3, threshold=0.4, pause=0.2):
    """Avance prudemment un certain nombre de pas."""
    for _ in range(num_steps):
        motion_service.moveTo(step, 0.0, 0.0)
        time.sleep(pause)
        yield True
    motion_service.stopMove()


def grid_exploration_generator(motion_service, num_lines=3, line_length=0.7, lateral_step=0.2, pause=0.5):
    """
    Explore l'environnement selon un motif de grille systÃ©matique (Boustrophedon).
    """
    print("Exploration: Grille SystÃ©matique (Couverture complÃ¨te)")
    turn_angle = math.pi / 2 
    
    for i in range(num_lines):
        # 1. Avancer le long de la ligne
        print(f"Ligne {i+1}: Avance de {line_length}m")
        motion_service.moveTo(line_length, 0.0, 0.0)
        time.sleep(pause)
        yield True 

        # --- DÃ©termination du prochain virage pour passer Ã  la ligne suivante ---
        if i < num_lines - 1:
            # 2. Tourner 90Â° (prÃ©paration au pas latÃ©ral)
            angle = -turn_angle if i % 2 == 0 else turn_angle
            motion_service.moveTo(0.0, 0.0, angle)
            time.sleep(pause)
            yield True

            # 3. Avance latÃ©rale courte
            print(f"Ligne {i+1}: Pas latÃ©ral de {lateral_step}m")
            motion_service.moveTo(lateral_step, 0.0, 0.0) 
            time.sleep(pause)
            yield True

            # 4. Tourner 90Â° pour se remettre dans l'axe de la ligne suivante
            motion_service.moveTo(0.0, 0.0, angle)
            time.sleep(pause)
            yield True

    motion_service.stopMove()
    print("Exploration en grille terminÃ©e.")


# ==============================================================
# === FONCTION PRINCIPALE OPTIMISÃ‰E ============================
# ==============================================================

def optimised_search_cycle(session, video_service, model, class_names, tts, name_id):
    """
    ExÃ©cute un cycle de recherche optimal : rotation visuelle, puis exploration en grille.
    """
    motion_service = session.service("ALMotion")
    posture_service = session.service("ALRobotPosture")
    sonar_service = session.service("ALSonar")
    memory_service = session.service("ALMemory")

    # Configuration de la sÃ©curitÃ© et de la posture
    sonar_service.subscribe("ObstacleDetector")
    time.sleep(0.5)
    motion_service.wakeUp()
    posture_service.goToPosture("StandInit", 1.0)

    # StratÃ©gie : Rotation (Balayage rapide) puis Grille (Couverture complÃ¨te)
    exploration_phases = [
        ("Rotation Balayage", rotate_on_place_generator(motion_service, num_steps=8)),
        ("Grille SystÃ©matique", grid_exploration_generator(motion_service, num_lines=3, line_length=0.7)) 
    ]

    detected_object = None
    
    # ItÃ©ration Ã  travers les phases
    for phase_name, explorer in exploration_phases:
        print(f"\n--- ðŸ§­ Phase : {phase_name} ---")

        for _ in explorer: # Le gÃ©nÃ©rateur met le corps en mouvement
            
            # --- Balayage de TÃªte + DÃ©tection ---
            for head_yaw in [-0.5, 0.0, 0.5]: 
                
                # ðŸ›¡ï¸ GESTION DE LA DÃ‰CONNEXION lors du mouvement de tÃªte
                try:
                    motion_service.setAngles("HeadYaw", head_yaw, 0.2)
                    time.sleep(0.3) 
                except RuntimeError as e:
                    print(f"[{time.strftime('%H:%M:%S')}] ðŸš¨ Connexion perdue lors du mouvement : {e}. Sortie forcÃ©e.")
                    detected_object = True 
                    break 

                # Capture camÃ©ra
                frame = get_frame(video_service, name_id)
                if frame is None:
                    continue

                # ðŸ’¡ VÃ‰RIFICATION ANTI-Ã‰CRAN NOIR : Si l'image est trop sombre, la sauter
                mean_brightness = frame.mean() 
                if mean_brightness < 10.0:
                    # print(f"[{time.strftime('%H:%M:%S')}] ðŸš§ Image trop sombre (moyenne: {mean_brightness:.1f}), sautÃ©e.")
                    continue
                
                # ðŸ” DÃ©tection visuelle (Nao cible et QRCode)
                detected, class_name, confidence = detect_nao(frame, model, class_names, threshold=0.95)

                # âœ… AFFICHAGE EN PERMANENCE
                label = f"{class_name} - {confidence*100:.1f}%"
                print(f"ðŸ” IA â†’ Classe: {class_name} | Confiance: {confidence:.3f}")

                color = (0, 255, 0) if detected else (0, 180, 255)
                cv2.putText(frame, label, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                cv2.imshow("ðŸ“· Vue NAO (dÃ©tection)", frame)

                key = cv2.waitKey(1) & 0xFF
                if key == 27:
                    print("â›” ArrÃªt manuel via la fenÃªtre vidÃ©o.")
                    motion_service.stopMove()
                    detected_object = True 
                    break

                # âœ… Si NAO dÃ©tectÃ© : arrÃªt immÃ©diat
                if detected:
                    print(f"âœ… NAO dÃ©tectÃ© : {label}")
                    tts.say(f"J'ai trouvÃ© un {class_name}")
                    detected_object = class_name
                    motion_service.stopMove()
                    break 

            if detected_object:
                break 
            
            # --- Gestion des obstacles (Sonar) ---
            left = memory_service.getData("Device/SubDeviceList/US/Left/Sensor/Value")
            right = memory_service.getData("Device/SubDeviceList/US/Right/Sensor/Value")
            if min(left, right) < 0.40:
                print("âš ï¸ Obstacle dÃ©tectÃ©, rotation d'Ã©vitement.")
                # ðŸ›¡ï¸ GESTION DE LA DÃ‰CONNEXION lors de l'Ã©vitement
                try:
                    motion_service.stopMove()
                    if left > right:
                        motion_service.moveTo(0, 0, 1.57) # Tourne Ã  gauche
                    else:
                        motion_service.moveTo(0, 0, -1.57) # Tourne Ã  droite
                    time.sleep(1.0) 
                except RuntimeError as e:
                    print(f"[{time.strftime('%H:%M:%S')}] ðŸš¨ Connexion perdue lors de l'Ã©vitement : {e}. ArrÃªt.")
                    detected_object = True
                    break
        
        if detected_object:
            break
    
    # --- Nettoyage Final ---
    motion_service.setAngles("HeadYaw", 0.0, 0.2)
    sonar_service.unsubscribe("ObstacleDetector")
    cv2.destroyAllWindows()
    motion_service.rest()
    print("âœ… Cycle de recherche terminÃ© proprement.")

    return detected_object is not None